{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Dive and Preparation in Python\n",
    "\n",
    "In this notebook, we will explore how to evaluate and clean variables in a dataset using Python. \n",
    "We will also perform basic exploratory data analysis (EDA) to understand the structure and contents \n",
    "of the dataset and make any necessary modifications for analysis.\n",
    "\n",
    "## What is Exploratory Data Analysis (EDA)?\n",
    "\n",
    "Exploratory Data Analysis (EDA) refers to the process of investigating datasets to summarize their main characteristics. \n",
    "It often involves understanding variable distributions, relationships between variables, and checking for anomalies \n",
    "such as missing values or outliers. The primary objectives of EDA are to:\n",
    "\n",
    "1. **Understand the structure** of the dataset.\n",
    "2. **Detect outliers** or anomalies.\n",
    "3. **Identify missing data** and plan for handling it.\n",
    "4. **Create or derive new variables** if necessary for analysis.\n",
    "5. **Prepare the data** for statistical analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Exploring the Data\n",
    "\n",
    "First, we load the `pandas` and `numpy` libraries, and read in our dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OPEID</th>\n",
       "      <th>name</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>region</th>\n",
       "      <th>median_debt</th>\n",
       "      <th>default_rate</th>\n",
       "      <th>highest_degree</th>\n",
       "      <th>ownership</th>\n",
       "      <th>locale</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_cost</th>\n",
       "      <th>net_tuition</th>\n",
       "      <th>ed_spending_per_student</th>\n",
       "      <th>avg_faculty_salary</th>\n",
       "      <th>pct_PELL</th>\n",
       "      <th>pct_fed_loan</th>\n",
       "      <th>grad_rate</th>\n",
       "      <th>pct_firstgen</th>\n",
       "      <th>med_fam_income</th>\n",
       "      <th>med_alum_earnings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100200</td>\n",
       "      <td>Alabama A &amp; M University</td>\n",
       "      <td>Normal</td>\n",
       "      <td>AL</td>\n",
       "      <td>South</td>\n",
       "      <td>15.250</td>\n",
       "      <td>12.1</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Public</td>\n",
       "      <td>Small City</td>\n",
       "      <td>...</td>\n",
       "      <td>23.445</td>\n",
       "      <td>8.101</td>\n",
       "      <td>4.836</td>\n",
       "      <td>7.599</td>\n",
       "      <td>70.95</td>\n",
       "      <td>75.04</td>\n",
       "      <td>28.66</td>\n",
       "      <td>36.582809</td>\n",
       "      <td>23.5530</td>\n",
       "      <td>36.339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>105200</td>\n",
       "      <td>University of Alabama at Birmingham</td>\n",
       "      <td>Birmingham</td>\n",
       "      <td>AL</td>\n",
       "      <td>South</td>\n",
       "      <td>15.085</td>\n",
       "      <td>4.8</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Public</td>\n",
       "      <td>Small City</td>\n",
       "      <td>...</td>\n",
       "      <td>25.542</td>\n",
       "      <td>11.986</td>\n",
       "      <td>14.691</td>\n",
       "      <td>11.380</td>\n",
       "      <td>33.97</td>\n",
       "      <td>46.88</td>\n",
       "      <td>61.17</td>\n",
       "      <td>34.122367</td>\n",
       "      <td>34.4890</td>\n",
       "      <td>46.990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2503400</td>\n",
       "      <td>Amridge University</td>\n",
       "      <td>Montgomery</td>\n",
       "      <td>AL</td>\n",
       "      <td>South</td>\n",
       "      <td>10.984</td>\n",
       "      <td>12.9</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Private nonprofit</td>\n",
       "      <td>Small City</td>\n",
       "      <td>...</td>\n",
       "      <td>20.100</td>\n",
       "      <td>13.890</td>\n",
       "      <td>3.664</td>\n",
       "      <td>4.545</td>\n",
       "      <td>74.52</td>\n",
       "      <td>84.93</td>\n",
       "      <td>25.00</td>\n",
       "      <td>51.250000</td>\n",
       "      <td>15.0335</td>\n",
       "      <td>37.895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>105500</td>\n",
       "      <td>University of Alabama in Huntsville</td>\n",
       "      <td>Huntsville</td>\n",
       "      <td>AL</td>\n",
       "      <td>South</td>\n",
       "      <td>14.000</td>\n",
       "      <td>4.7</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Public</td>\n",
       "      <td>Small City</td>\n",
       "      <td>...</td>\n",
       "      <td>24.861</td>\n",
       "      <td>8.279</td>\n",
       "      <td>8.320</td>\n",
       "      <td>9.697</td>\n",
       "      <td>24.03</td>\n",
       "      <td>38.55</td>\n",
       "      <td>57.14</td>\n",
       "      <td>31.013216</td>\n",
       "      <td>44.7870</td>\n",
       "      <td>54.361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100500</td>\n",
       "      <td>Alabama State University</td>\n",
       "      <td>Montgomery</td>\n",
       "      <td>AL</td>\n",
       "      <td>South</td>\n",
       "      <td>17.500</td>\n",
       "      <td>12.8</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Public</td>\n",
       "      <td>Small City</td>\n",
       "      <td>...</td>\n",
       "      <td>21.892</td>\n",
       "      <td>9.302</td>\n",
       "      <td>9.579</td>\n",
       "      <td>7.194</td>\n",
       "      <td>73.68</td>\n",
       "      <td>78.05</td>\n",
       "      <td>31.77</td>\n",
       "      <td>34.343434</td>\n",
       "      <td>22.0805</td>\n",
       "      <td>32.084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     OPEID                                 name        city state region  \\\n",
       "0   100200             Alabama A & M University      Normal    AL  South   \n",
       "1   105200  University of Alabama at Birmingham  Birmingham    AL  South   \n",
       "2  2503400                   Amridge University  Montgomery    AL  South   \n",
       "3   105500  University of Alabama in Huntsville  Huntsville    AL  South   \n",
       "4   100500             Alabama State University  Montgomery    AL  South   \n",
       "\n",
       "   median_debt  default_rate highest_degree          ownership      locale  \\\n",
       "0       15.250          12.1       Graduate             Public  Small City   \n",
       "1       15.085           4.8       Graduate             Public  Small City   \n",
       "2       10.984          12.9       Graduate  Private nonprofit  Small City   \n",
       "3       14.000           4.7       Graduate             Public  Small City   \n",
       "4       17.500          12.8       Graduate             Public  Small City   \n",
       "\n",
       "   ... avg_cost  net_tuition  ed_spending_per_student avg_faculty_salary  \\\n",
       "0  ...   23.445        8.101                    4.836              7.599   \n",
       "1  ...   25.542       11.986                   14.691             11.380   \n",
       "2  ...   20.100       13.890                    3.664              4.545   \n",
       "3  ...   24.861        8.279                    8.320              9.697   \n",
       "4  ...   21.892        9.302                    9.579              7.194   \n",
       "\n",
       "   pct_PELL  pct_fed_loan  grad_rate  pct_firstgen  med_fam_income  \\\n",
       "0     70.95         75.04      28.66     36.582809         23.5530   \n",
       "1     33.97         46.88      61.17     34.122367         34.4890   \n",
       "2     74.52         84.93      25.00     51.250000         15.0335   \n",
       "3     24.03         38.55      57.14     31.013216         44.7870   \n",
       "4     73.68         78.05      31.77     34.343434         22.0805   \n",
       "\n",
       "   med_alum_earnings  \n",
       "0             36.339  \n",
       "1             46.990  \n",
       "2             37.895  \n",
       "3             54.361  \n",
       "4             32.084  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Loading the dataset\n",
    "college_data = pd.read_csv('data/colleges.csv')\n",
    "\n",
    "# Preview the first few rows of the dataset\n",
    "college_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We will check the dataset's basic structure including the number of rows, columns, and data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data structure\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4435 entries, 0 to 4434\n",
      "Data columns (total 26 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   OPEID                    4435 non-null   int64  \n",
      " 1   name                     4435 non-null   object \n",
      " 2   city                     4435 non-null   object \n",
      " 3   state                    4435 non-null   object \n",
      " 4   region                   4435 non-null   object \n",
      " 5   median_debt              4435 non-null   float64\n",
      " 6   default_rate             4435 non-null   float64\n",
      " 7   highest_degree           4435 non-null   object \n",
      " 8   ownership                4435 non-null   object \n",
      " 9   locale                   4435 non-null   object \n",
      " 10  hbcu                     4435 non-null   object \n",
      " 11  admit_rate               1704 non-null   float64\n",
      " 12  SAT_avg                  1105 non-null   float64\n",
      " 13  online_only              4435 non-null   object \n",
      " 14  enrollment               4435 non-null   int64  \n",
      " 15  net_price                4435 non-null   float64\n",
      " 16  avg_cost                 4435 non-null   float64\n",
      " 17  net_tuition              4435 non-null   float64\n",
      " 18  ed_spending_per_student  4435 non-null   float64\n",
      " 19  avg_faculty_salary       3077 non-null   float64\n",
      " 20  pct_PELL                 4435 non-null   float64\n",
      " 21  pct_fed_loan             4435 non-null   float64\n",
      " 22  grad_rate                4435 non-null   float64\n",
      " 23  pct_firstgen             4088 non-null   float64\n",
      " 24  med_fam_income           4399 non-null   float64\n",
      " 25  med_alum_earnings        3912 non-null   float64\n",
      "dtypes: float64(15), int64(2), object(9)\n",
      "memory usage: 901.0+ KB\n",
      "None\n",
      "Statistical summary\n",
      "              OPEID  median_debt  default_rate   admit_rate      SAT_avg  \\\n",
      "count  4.435000e+03  4435.000000   4435.000000  1704.000000  1105.000000   \n",
      "mean   1.492464e+06    11.195790      9.060090    70.812576  1139.842534   \n",
      "std    1.976276e+06     5.319178      6.144554    20.567925   131.630792   \n",
      "min    1.002000e+05     1.932000      0.000000     2.440000   760.000000   \n",
      "25%    2.822000e+05     6.863000      4.400000    59.787500  1050.000000   \n",
      "50%    7.669000e+05     9.500000      8.200000    74.680000  1113.000000   \n",
      "75%    2.362002e+06    15.000000     12.300000    86.115000  1205.000000   \n",
      "max    7.209887e+07    33.470000     57.100000   100.000000  1566.000000   \n",
      "\n",
      "          enrollment    net_price     avg_cost  net_tuition  \\\n",
      "count    4435.000000  4435.000000  4435.000000  4435.000000   \n",
      "mean     3110.519053    17.371474    27.102880    10.836639   \n",
      "std      6429.445325     8.638514    14.988075     7.506410   \n",
      "min         0.000000    -0.407000     4.760000     0.000000   \n",
      "25%       171.000000    10.849000    16.452500     5.439500   \n",
      "50%       868.000000    16.757000    22.945000     9.912000   \n",
      "75%      2953.000000    22.470500    32.032500    14.218000   \n",
      "max    109233.000000   112.050000   120.377000    66.442000   \n",
      "\n",
      "       ed_spending_per_student  avg_faculty_salary     pct_PELL  pct_fed_loan  \\\n",
      "count              4435.000000         3077.000000  4435.000000   4435.000000   \n",
      "mean                  7.760832            7.266518    45.555540     49.069461   \n",
      "std                   6.881391            2.528365    20.309775     24.542281   \n",
      "min                   0.000000            0.897000     0.000000      0.000000   \n",
      "25%                   4.126000            5.610000    29.830000     30.925000   \n",
      "50%                   6.352000            6.958000    42.500000     52.540000   \n",
      "75%                   9.342000            8.573000    60.380000     67.680000   \n",
      "max                 139.766000           21.143000   100.000000    100.000000   \n",
      "\n",
      "         grad_rate  pct_firstgen  med_fam_income  med_alum_earnings  \n",
      "count  4435.000000   4088.000000     4399.000000        3912.000000  \n",
      "mean     54.945651     43.357756       31.791930          40.007157  \n",
      "std      22.051351     12.931312       20.811117          14.486256  \n",
      "min       0.000000      8.866995        0.000000          10.939000  \n",
      "25%      37.310000     35.006281       17.827750          29.720250  \n",
      "50%      56.400000     45.102178       24.670000          38.056000  \n",
      "75%      71.915000     52.599727       39.516500          47.381250  \n",
      "max     100.000000     85.906040      179.864000         132.969000  \n",
      "Summary of categorical variables\n",
      "                     name      city state   region highest_degree  \\\n",
      "count                4435      4435  4435     4435           4435   \n",
      "unique               4357      1943    54        7              4   \n",
      "top     Cortiva Institute  New York    CA  Midwest       Graduate   \n",
      "freq                    6        51   423     1074           1464   \n",
      "\n",
      "                 ownership  locale  hbcu online_only  \n",
      "count                 4435    4435  4435        4435  \n",
      "unique                   3       5     2           2  \n",
      "top     Prviate for-profit  Suburb    No          No  \n",
      "freq                  1684    1311  4348        4413  \n"
     ]
    }
   ],
   "source": [
    "# Checking the structure of the dataset\n",
    "print(\"Data structure\")\n",
    "print(college_data.info())\n",
    "\n",
    "# Getting a statistical summary of numeric variables\n",
    "print(\"Statistical summary\")\n",
    "print(college_data.describe(include=[np.number]))\n",
    "\n",
    "# Getting a statistical summary of categorical variables\n",
    "print(\"Summary of categorical variables\")\n",
    "print(college_data.describe(include=[object]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Making a Copy of the Original Data for Processing\n",
    "\n",
    "We will create a copy of the dataset to keep the original raw data intact. This is useful for checking our work later.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a copy of the dataset for modification\n",
    "college_data_cleaned = college_data.copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating an index\n",
    "\n",
    "Our dataset already has an ID variable, but adding an index can help us track the order of the observations. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": [
     "showcomments"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OPEID</th>\n",
       "      <th>name</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100200</td>\n",
       "      <td>Alabama A &amp; M University</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>105200</td>\n",
       "      <td>University of Alabama at Birmingham</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2503400</td>\n",
       "      <td>Amridge University</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>105500</td>\n",
       "      <td>University of Alabama in Huntsville</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100500</td>\n",
       "      <td>Alabama State University</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>105100</td>\n",
       "      <td>The University of Alabama</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100700</td>\n",
       "      <td>Central Alabama Community College</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>831000</td>\n",
       "      <td>Auburn University at Montgomery</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>100900</td>\n",
       "      <td>Auburn University</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>101200</td>\n",
       "      <td>Birmingham-Southern College</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     OPEID                                 name  index\n",
       "0   100200             Alabama A & M University      0\n",
       "1   105200  University of Alabama at Birmingham      1\n",
       "2  2503400                   Amridge University      2\n",
       "3   105500  University of Alabama in Huntsville      3\n",
       "4   100500             Alabama State University      4\n",
       "5   105100            The University of Alabama      5\n",
       "6   100700    Central Alabama Community College      6\n",
       "7   831000      Auburn University at Montgomery      7\n",
       "8   100900                    Auburn University      8\n",
       "9   101200          Birmingham-Southern College      9"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# making a copy of data frame for modification\n",
    "college_data_cleaned = college_data.copy()\n",
    "\n",
    "# first we will find the sample size (the number of rows)\n",
    "sampsize = college_data_cleaned.shape[0]\n",
    "\n",
    "# then we will create an index that ranges from to \n",
    "# GOOD CODING PRACTIC: DON'T HARD CODE THE SAMPLE SIZE\n",
    "college_data_cleaned['index'] = pd.Series(range(0,sampsize))\n",
    "\n",
    "# Check \n",
    "college_data_cleaned[['OPEID','name','index']].head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Outliers & Unexpected Values\n",
    "\n",
    "We will identify potential outliers in variables such as `SAT_avg` and replace values that are outside reasonable bounds.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "showmarkers"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OPEID</th>\n",
       "      <th>median_debt</th>\n",
       "      <th>default_rate</th>\n",
       "      <th>admit_rate</th>\n",
       "      <th>SAT_avg</th>\n",
       "      <th>enrollment</th>\n",
       "      <th>net_price</th>\n",
       "      <th>avg_cost</th>\n",
       "      <th>net_tuition</th>\n",
       "      <th>ed_spending_per_student</th>\n",
       "      <th>avg_faculty_salary</th>\n",
       "      <th>pct_PELL</th>\n",
       "      <th>pct_fed_loan</th>\n",
       "      <th>grad_rate</th>\n",
       "      <th>pct_firstgen</th>\n",
       "      <th>med_fam_income</th>\n",
       "      <th>med_alum_earnings</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.435000e+03</td>\n",
       "      <td>4435.000000</td>\n",
       "      <td>4435.000000</td>\n",
       "      <td>1704.000000</td>\n",
       "      <td>1105.000000</td>\n",
       "      <td>4435.000000</td>\n",
       "      <td>4435.000000</td>\n",
       "      <td>4435.000000</td>\n",
       "      <td>4435.000000</td>\n",
       "      <td>4435.000000</td>\n",
       "      <td>3077.000000</td>\n",
       "      <td>4435.000000</td>\n",
       "      <td>4435.000000</td>\n",
       "      <td>4435.000000</td>\n",
       "      <td>4088.000000</td>\n",
       "      <td>4399.000000</td>\n",
       "      <td>3912.000000</td>\n",
       "      <td>4435.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.492464e+06</td>\n",
       "      <td>11.195790</td>\n",
       "      <td>9.060090</td>\n",
       "      <td>70.812576</td>\n",
       "      <td>1139.842534</td>\n",
       "      <td>3110.519053</td>\n",
       "      <td>17.371474</td>\n",
       "      <td>27.102880</td>\n",
       "      <td>10.836639</td>\n",
       "      <td>7.760832</td>\n",
       "      <td>7.266518</td>\n",
       "      <td>45.555540</td>\n",
       "      <td>49.069461</td>\n",
       "      <td>54.945651</td>\n",
       "      <td>43.357756</td>\n",
       "      <td>31.791930</td>\n",
       "      <td>40.007157</td>\n",
       "      <td>2217.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.976276e+06</td>\n",
       "      <td>5.319178</td>\n",
       "      <td>6.144554</td>\n",
       "      <td>20.567925</td>\n",
       "      <td>131.630792</td>\n",
       "      <td>6429.445325</td>\n",
       "      <td>8.638514</td>\n",
       "      <td>14.988075</td>\n",
       "      <td>7.506410</td>\n",
       "      <td>6.881391</td>\n",
       "      <td>2.528365</td>\n",
       "      <td>20.309775</td>\n",
       "      <td>24.542281</td>\n",
       "      <td>22.051351</td>\n",
       "      <td>12.931312</td>\n",
       "      <td>20.811117</td>\n",
       "      <td>14.486256</td>\n",
       "      <td>1280.418551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.002000e+05</td>\n",
       "      <td>1.932000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.440000</td>\n",
       "      <td>760.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.407000</td>\n",
       "      <td>4.760000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.897000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.866995</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.939000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.822000e+05</td>\n",
       "      <td>6.863000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>59.787500</td>\n",
       "      <td>1050.000000</td>\n",
       "      <td>171.000000</td>\n",
       "      <td>10.849000</td>\n",
       "      <td>16.452500</td>\n",
       "      <td>5.439500</td>\n",
       "      <td>4.126000</td>\n",
       "      <td>5.610000</td>\n",
       "      <td>29.830000</td>\n",
       "      <td>30.925000</td>\n",
       "      <td>37.310000</td>\n",
       "      <td>35.006281</td>\n",
       "      <td>17.827750</td>\n",
       "      <td>29.720250</td>\n",
       "      <td>1108.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.669000e+05</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>8.200000</td>\n",
       "      <td>74.680000</td>\n",
       "      <td>1113.000000</td>\n",
       "      <td>868.000000</td>\n",
       "      <td>16.757000</td>\n",
       "      <td>22.945000</td>\n",
       "      <td>9.912000</td>\n",
       "      <td>6.352000</td>\n",
       "      <td>6.958000</td>\n",
       "      <td>42.500000</td>\n",
       "      <td>52.540000</td>\n",
       "      <td>56.400000</td>\n",
       "      <td>45.102178</td>\n",
       "      <td>24.670000</td>\n",
       "      <td>38.056000</td>\n",
       "      <td>2217.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.362002e+06</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>12.300000</td>\n",
       "      <td>86.115000</td>\n",
       "      <td>1205.000000</td>\n",
       "      <td>2953.000000</td>\n",
       "      <td>22.470500</td>\n",
       "      <td>32.032500</td>\n",
       "      <td>14.218000</td>\n",
       "      <td>9.342000</td>\n",
       "      <td>8.573000</td>\n",
       "      <td>60.380000</td>\n",
       "      <td>67.680000</td>\n",
       "      <td>71.915000</td>\n",
       "      <td>52.599727</td>\n",
       "      <td>39.516500</td>\n",
       "      <td>47.381250</td>\n",
       "      <td>3325.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.209887e+07</td>\n",
       "      <td>33.470000</td>\n",
       "      <td>57.100000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1566.000000</td>\n",
       "      <td>109233.000000</td>\n",
       "      <td>112.050000</td>\n",
       "      <td>120.377000</td>\n",
       "      <td>66.442000</td>\n",
       "      <td>139.766000</td>\n",
       "      <td>21.143000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>85.906040</td>\n",
       "      <td>179.864000</td>\n",
       "      <td>132.969000</td>\n",
       "      <td>4434.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              OPEID  median_debt  default_rate   admit_rate      SAT_avg  \\\n",
       "count  4.435000e+03  4435.000000   4435.000000  1704.000000  1105.000000   \n",
       "mean   1.492464e+06    11.195790      9.060090    70.812576  1139.842534   \n",
       "std    1.976276e+06     5.319178      6.144554    20.567925   131.630792   \n",
       "min    1.002000e+05     1.932000      0.000000     2.440000   760.000000   \n",
       "25%    2.822000e+05     6.863000      4.400000    59.787500  1050.000000   \n",
       "50%    7.669000e+05     9.500000      8.200000    74.680000  1113.000000   \n",
       "75%    2.362002e+06    15.000000     12.300000    86.115000  1205.000000   \n",
       "max    7.209887e+07    33.470000     57.100000   100.000000  1566.000000   \n",
       "\n",
       "          enrollment    net_price     avg_cost  net_tuition  \\\n",
       "count    4435.000000  4435.000000  4435.000000  4435.000000   \n",
       "mean     3110.519053    17.371474    27.102880    10.836639   \n",
       "std      6429.445325     8.638514    14.988075     7.506410   \n",
       "min         0.000000    -0.407000     4.760000     0.000000   \n",
       "25%       171.000000    10.849000    16.452500     5.439500   \n",
       "50%       868.000000    16.757000    22.945000     9.912000   \n",
       "75%      2953.000000    22.470500    32.032500    14.218000   \n",
       "max    109233.000000   112.050000   120.377000    66.442000   \n",
       "\n",
       "       ed_spending_per_student  avg_faculty_salary     pct_PELL  pct_fed_loan  \\\n",
       "count              4435.000000         3077.000000  4435.000000   4435.000000   \n",
       "mean                  7.760832            7.266518    45.555540     49.069461   \n",
       "std                   6.881391            2.528365    20.309775     24.542281   \n",
       "min                   0.000000            0.897000     0.000000      0.000000   \n",
       "25%                   4.126000            5.610000    29.830000     30.925000   \n",
       "50%                   6.352000            6.958000    42.500000     52.540000   \n",
       "75%                   9.342000            8.573000    60.380000     67.680000   \n",
       "max                 139.766000           21.143000   100.000000    100.000000   \n",
       "\n",
       "         grad_rate  pct_firstgen  med_fam_income  med_alum_earnings  \\\n",
       "count  4435.000000   4088.000000     4399.000000        3912.000000   \n",
       "mean     54.945651     43.357756       31.791930          40.007157   \n",
       "std      22.051351     12.931312       20.811117          14.486256   \n",
       "min       0.000000      8.866995        0.000000          10.939000   \n",
       "25%      37.310000     35.006281       17.827750          29.720250   \n",
       "50%      56.400000     45.102178       24.670000          38.056000   \n",
       "75%      71.915000     52.599727       39.516500          47.381250   \n",
       "max     100.000000     85.906040      179.864000         132.969000   \n",
       "\n",
       "             index  \n",
       "count  4435.000000  \n",
       "mean   2217.000000  \n",
       "std    1280.418551  \n",
       "min       0.000000  \n",
       "25%    1108.500000  \n",
       "50%    2217.000000  \n",
       "75%    3325.500000  \n",
       "max    4434.000000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# describe the the numeric data\n",
    "college_data_cleaned.describe(include=[np.number])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For illustrative purposes (realizing this doesn't match reality), let's imagine the highest SAT possible was 1500. We will assume anything higher is a mistake and set the value to missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The max of SAT_avg before:1566.0\n",
      "The max of SAT_avg after:1500.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# This is what the code does:\n",
    "  ## It's looking at each row in the collegeDat DataFrame.\n",
    "  ## Wherever the value of 'SAT_avg' in that DataFrame is greater than 1500,\n",
    "  ##  it goes to the corresponding row in the collegeDat_mod DataFrame.\n",
    "  ## In the 'SAT_avg' column of collegeDat_mod, it replaces those values with np.nan for missing.\n",
    "college_data_cleaned.loc[college_data['SAT_avg'] > 1500, 'SAT_avg'] = np.nan\n",
    "\n",
    "  # check \n",
    "maxSAT = college_data['SAT_avg'].max()\n",
    "maxSAT_mod = college_data_cleaned['SAT_avg'].max()\n",
    "print(\"The max of SAT_avg before:\" + str(maxSAT))\n",
    "print(\"The max of SAT_avg after:\" + str(maxSAT_mod))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine character data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     name      city state   region highest_degree  \\\n",
      "count                4435      4435  4435     4435           4435   \n",
      "unique               4357      1943    54        7              4   \n",
      "top     Cortiva Institute  New York    CA  Midwest       Graduate   \n",
      "freq                    6        51   423     1074           1464   \n",
      "\n",
      "                 ownership  locale  hbcu online_only  \n",
      "count                 4435    4435  4435        4435  \n",
      "unique                   3       5     2           2  \n",
      "top     Prviate for-profit  Suburb    No          No  \n",
      "freq                  1684    1311  4348        4413  \n",
      "['Graduate' 'Associates' 'Bachelors' 'Certificate']\n",
      "['Public' 'Private nonprofit' 'Prviate for-profit']\n"
     ]
    }
   ],
   "source": [
    "# describe the character data \n",
    "print(college_data.describe(include=[object]))\n",
    "\n",
    "# this doesn't give enough information \n",
    "# what if some categories are slightly different but mean the same thing?\n",
    "\n",
    "print(college_data_cleaned['highest_degree'].unique()) # looks good\n",
    "print(college_data_cleaned['ownership'].unique()) # looks good\n",
    "# etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling categorical data\n",
    "\n",
    "#### Converting categorical data to dummies\n",
    "\n",
    "Note: The example in the book is probably not a typical task - converting school categories to numeric grades. More often, we want to turn categories into a series of booleans that let us know whether an observation belongs to the category. This is sometimes referred to as \"one-hot\" coding. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Associates  Bachelors  Certificate  Graduate\n",
      "0       False      False        False      True\n",
      "1       False      False        False      True\n",
      "2       False      False        False      True\n",
      "3       False      False        False      True\n",
      "4       False      False        False      True\n",
      "   Associates  Bachelors  Certificate  Graduate\n",
      "0           0          0            0         1\n",
      "1           0          0            0         1\n",
      "2           0          0            0         1\n",
      "3           0          0            0         1\n",
      "4           0          0            0         1\n"
     ]
    }
   ],
   "source": [
    "# the get_dummies function creates all the variables we need\n",
    "# these are in a new data frame\n",
    "highest_degree_dummies = pd.get_dummies(college_data_cleaned['highest_degree'])\n",
    "\n",
    "# let's see what these look like\n",
    "print(highest_degree_dummies.head(5))\n",
    "\n",
    "# let's convert them to 0/1 for TRUE/FALSE\n",
    "highest_degree_dummies = highest_degree_dummies.astype(int)\n",
    "\n",
    "# let's take another look\n",
    "print(highest_degree_dummies.head(5))\n",
    "\n",
    "# add these to collegeDat_mod\n",
    "college_data_cleaned = pd.concat([college_data_cleaned,highest_degree_dummies], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating new categorical variables\n",
    "\n",
    "There will be other times that we want to convert numeric data to categories. For example, we might create \"bins\" of averge SAT scores - such as low, medium and high scores. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking SAT_avg_category creation\n",
      "   SAT_avg SAT_avg_category\n",
      "0    959.0              low\n",
      "1   1245.0           medium\n",
      "2      NaN              NaN\n",
      "3   1300.0           medium\n",
      "4    938.0              low\n",
      "5   1262.0           medium\n",
      "6      NaN              NaN\n",
      "7   1061.0           medium\n",
      "8   1302.0             high\n",
      "9   1202.0           medium\n",
      "Check creation of missing category\n",
      "   SAT_avg SAT_avg_category\n",
      "0    959.0              low\n",
      "1   1245.0           medium\n",
      "2      NaN          missing\n",
      "3   1300.0           medium\n",
      "4    938.0              low\n",
      "5   1262.0           medium\n",
      "6      NaN          missing\n",
      "7   1061.0           medium\n",
      "8   1302.0             high\n",
      "9   1202.0           medium\n"
     ]
    }
   ],
   "source": [
    "# defining the edges of the bins\n",
    "bins = [400, 1000, 1300, 1600]  \n",
    "\n",
    "# defining the labels for your bins\n",
    "labels = ['low', 'medium', 'high']\n",
    "\n",
    "# creating new variable using cut function\n",
    "college_data_cleaned['SAT_avg_category'] = pd.cut(college_data_cleaned['SAT_avg'], bins=bins, labels=labels, include_lowest=True)\n",
    "\n",
    "# check \n",
    "print(\"Checking SAT_avg_category creation\")\n",
    "print(college_data_cleaned[['SAT_avg','SAT_avg_category']].head(10))\n",
    "\n",
    "# we could also create a category for missing\n",
    "college_data_cleaned['SAT_avg_category'] = college_data_cleaned['SAT_avg_category'].astype('object')  # Ensure it's of object type in order to hold string\n",
    "SAT_miss_which = college_data_cleaned['SAT_avg'].isna()\n",
    "college_data_cleaned.loc[SAT_miss_which, 'SAT_avg_category'] = 'missing'\n",
    "\n",
    "# check\n",
    "print(\"Check creation of missing category\")\n",
    "print(college_data_cleaned[['SAT_avg','SAT_avg_category']].head(10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some notes about missing data\n",
    "\n",
    "Missing data is almost a universal phenomenon in data analyses. It is rare for a real-world dataset to contain complete information with valid values for every variable on every observation. Instead, missing information, data corruption, incomplete surveys, etc. are very common. Other times, strange data values that may be the consequence of data entry mistakes may need to be changed to be missing. \n",
    "\n",
    "One may be inclined to \"fill in\" missing data points with plausible values. This is referred to as \"imputation.\"  While this practice solves the operational difficulty that missing data impose, it can potentially create statistical problems such as distorted estimates of statistical summaries , understated standard\n",
    "errors, and in general, misleading results. There are some complex statistical methods for imputation that can be beneficial in some contexts, but these are beyond the scope of this class. \n",
    "\n",
    "Without imputation, observations with missing values for any variables included in an analysis will need to be excluded. This is often referred to as case-wise deletion (sometimes referred to as list-wise deletion). Case-wise deletion is the default method in most statistical software packages, including and R and Python. The method is attractive for its simplicity. It can be used for any kind of data analysis and requires no special computational methods. In particular, if the data are missing completely at random then the reduced sample will be a random sub-sample of the original sample. Data are said to be missing completely at random if the probability of missing data for a given variable is unrelated to its value and unrelated to the value of any other variable. That is, there is no pattern that can explain the reason for the variable being missing; the missingness occurs randomly. This implies that for any analysis, the results still generalize to the population represented in your full dataset. If data are not missing completely at random, then your findings may not generalize to the larger population. For example, if your data comes from a survey and younger people are more likely to have missing responses than older people, then your findings may not generalize as well to younger people. \n",
    "\n",
    "Another option that may work for some analyses, but not all, is to include the missingness in your analyses by capturing it as a category as we did above. You still won't have information for the variable with the missing value (e.g. average SAT score of students at the college) but if want to look at how average SAT score relates average cost, you can see how missingness is part of the story. \n",
    "\n",
    "Here are some notes about coding to deal with missing data in Python `pandas`:\n",
    "- Representation of Missing Values: In Pandas, missing values are generally represented by NaN (Not a Number) for numerical data (as we saw above) and None or NaN for object data types\n",
    "- Detecting Missing Values: Pandas offers functions like isna() or isnull() to detect missing values. These functions return a boolean mask over the data indicating whether an element is missing.\n",
    "- Calculations on Variables with Missing Values: functions like `mean`, `sum` and similar statistical functions will, by default, ignore the missing values. That is, it will automaticlaly do casewise deletion. \n",
    "\n",
    "Main summary: Check for missing values. If you jump straight to computing statistics, you may not realize you have missing values. Be thoughtful about the implications of your missing values. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OPEID                         0\n",
       "name                          0\n",
       "city                          0\n",
       "state                         0\n",
       "region                        0\n",
       "median_debt                   0\n",
       "default_rate                  0\n",
       "highest_degree                0\n",
       "ownership                     0\n",
       "locale                        0\n",
       "hbcu                          0\n",
       "admit_rate                 2731\n",
       "SAT_avg                    3348\n",
       "online_only                   0\n",
       "enrollment                    0\n",
       "net_price                     0\n",
       "avg_cost                      0\n",
       "net_tuition                   0\n",
       "ed_spending_per_student       0\n",
       "avg_faculty_salary         1358\n",
       "pct_PELL                      0\n",
       "pct_fed_loan                  0\n",
       "grad_rate                     0\n",
       "pct_firstgen                347\n",
       "med_fam_income               36\n",
       "med_alum_earnings           523\n",
       "index                         0\n",
       "Associates                    0\n",
       "Bachelors                     0\n",
       "Certificate                   0\n",
       "Graduate                      0\n",
       "SAT_avg_category              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for  missing values\n",
    "college_data_cleaned.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standardize variables\n",
    "\n",
    "Finally, you read about \"standardizing\" numeric variables. This means we center the variables around their mean and we convert the units of measurement of the variable to units of standard deviations. To do this, for each value of the variable, we substract the mean of the variable and divide by the standard deviation. In your reading, the method for doing this is illustrated when using the `scipy` package. Below, I show how to standardize a variable using `pandas`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.10288004509583\n",
      "14.98807514021403\n",
      "   avg_cost  avg_cost_std\n",
      "0    23.445     -0.244053\n",
      "1    25.542     -0.104141\n",
      "2    20.100     -0.467230\n",
      "3    24.861     -0.149578\n",
      "4    21.892     -0.347668\n",
      "5    30.016      0.194363\n",
      "6     9.437     -1.178662\n",
      "7    20.225     -0.458890\n",
      "8    32.196      0.339811\n",
      "9    32.514      0.361028\n",
      "-1.0253604304091637e-16\n"
     ]
    }
   ],
   "source": [
    "# Calculate the mean and standard deviation\n",
    "meanCost = college_data_cleaned['avg_cost'].mean()\n",
    "std_devCost = college_data_cleaned['avg_cost'].std()\n",
    "\n",
    "# Standardize the column\n",
    "college_data_cleaned['avg_cost_std'] = (college_data_cleaned['avg_cost'] - meanCost) / std_devCost\n",
    "\n",
    "# Check\n",
    "print(meanCost)\n",
    "print(std_devCost)\n",
    "print(college_data_cleaned[['avg_cost','avg_cost_std']].head(10))\n",
    "meanCost_std = college_data_cleaned['avg_cost_std'].mean() # should be close to zero\n",
    "print(meanCost_std)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IntroRPython",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
